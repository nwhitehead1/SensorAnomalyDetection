{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Network Latency & Anomaly Detecting using an LSTM Encoder-Decoder Model\n",
    "\n",
    "The goal of this project is twofold:\n",
    "- Reduce the network traffic in the cloud from the gateway layer.\n",
    "- Detect anomalous data, indicating a faulty sensor or a potential attack.\n",
    "\n",
    "We use a subset of data collected from Intel Labs between March and April, 2004 (http://db.csail.mit.edu/labdata/labdata.htmlO) as a proof of concept for applying Deep Learning at the IoT Gateway Layer.\n",
    "\n",
    "In the best case scenario, we can send predicted batches of time series data that are representative of the actual readings in $n/k$ transmissions, where $n$ is the size of our time series set, and $k$ is the batching size.\n",
    "\n",
    "In the worst case scenario, incorrectly predicted batch values will update what is currently in the cloud at the time of sensor reading. This scenario will perform as well as trivially passing data from the gateway to the cloud unhindered in $n$ transmissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data.txt.gz', 'rb') as data_bytes:\n",
    "    data = pd.read_csv(data_bytes, header=None, sep=' ', parse_dates=[[0, 1]], squeeze=True)\n",
    "data.columns = ['DATETIME','EPOCH','SENSOR_ID','TEMPERATURE','HUMIDITY','LIGHT','VOLTAGE']\n",
    "data = data.set_index('DATETIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2313682, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider sensor data between March 1st and March 10th for this experiment, as it contains the majority of the complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892574, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp = data.loc['2004-03-01':'2004-03-10'].copy()\n",
    "data_samp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of a proof of concept, we will make this a univariate problem (not including DateTime), focusing on Temperature readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp.drop(['HUMIDITY','LIGHT','VOLTAGE','EPOCH'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping any Sensor ID's where the value is NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp.dropna(subset=['SENSOR_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of out experiment, let us only consider sensors 1-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp = data_samp[(data_samp.SENSOR_ID >= 1) & (data_samp.SENSOR_ID <= 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the Sensor ID field to an integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp.SENSOR_ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SENSOR_ID        int64\n",
       "TEMPERATURE    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp.SENSOR_ID = data_samp.SENSOR_ID.astype(int)\n",
    "data_samp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENSOR_ID</th>\n",
       "      <th>TEMPERATURE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:01:57.130850</td>\n",
       "      <td>1</td>\n",
       "      <td>18.4498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:02:50.458234</td>\n",
       "      <td>1</td>\n",
       "      <td>18.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:04:26.606602</td>\n",
       "      <td>1</td>\n",
       "      <td>18.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:05:28.379208</td>\n",
       "      <td>1</td>\n",
       "      <td>18.4498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:05:50.456126</td>\n",
       "      <td>1</td>\n",
       "      <td>18.4302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SENSOR_ID  TEMPERATURE\n",
       "DATETIME                                          \n",
       "2004-03-01 00:01:57.130850          1      18.4498\n",
       "2004-03-01 00:02:50.458234          1      18.4400\n",
       "2004-03-01 00:04:26.606602          1      18.4400\n",
       "2004-03-01 00:05:28.379208          1      18.4498\n",
       "2004-03-01 00:05:50.456126          1      18.4302"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to measure the temperature at each sensor for a given timestamp, so we will pivot the table, making the column values sensor temperature readings at a given timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp = data_samp.pivot(columns='SENSOR_ID', values='TEMPERATURE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SENSOR_ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:00:21.445722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:00:22.429139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.8712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:00:25.633782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:00:52.381230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.8614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:00:53.317719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SENSOR_ID                   1        2   3   4   5   6        7   8       9   \\\n",
       "DATETIME                                                                       \n",
       "2004-03-01 00:00:21.445722 NaN      NaN NaN NaN NaN NaN      NaN NaN  18.489   \n",
       "2004-03-01 00:00:22.429139 NaN  18.8712 NaN NaN NaN NaN      NaN NaN     NaN   \n",
       "2004-03-01 00:00:25.633782 NaN      NaN NaN NaN NaN NaN  18.7144 NaN     NaN   \n",
       "2004-03-01 00:00:52.381230 NaN  18.8614 NaN NaN NaN NaN      NaN NaN     NaN   \n",
       "2004-03-01 00:00:53.317719 NaN      NaN NaN NaN NaN NaN  18.7046 NaN     NaN   \n",
       "\n",
       "SENSOR_ID                   10  \n",
       "DATETIME                        \n",
       "2004-03-01 00:00:21.445722 NaN  \n",
       "2004-03-01 00:00:22.429139 NaN  \n",
       "2004-03-01 00:00:25.633782 NaN  \n",
       "2004-03-01 00:00:52.381230 NaN  \n",
       "2004-03-01 00:00:53.317719 NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a lot of missing values for temperature readings in our table, due to micro-second DateTime ID's in our time series set. We will resample the data every 2 minutes, taking the mean of the values collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp = data_samp.resample('2min').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New resampled set has: 6754 data points.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SENSOR_ID\n",
       "1      143\n",
       "2      629\n",
       "3      114\n",
       "4      349\n",
       "5     6754\n",
       "6      582\n",
       "7       17\n",
       "8      753\n",
       "9       65\n",
       "10     163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('New resampled set has: {} data points.'.format(len(data_samp)))\n",
    "data_samp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly sensor 5 is not reading values between our time frame, so we will drop it. Stack brings the prescribed column (SENSOR_ID) into our index, making it easily dropped. We unstack to bring Sensor ID out of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = data_samp.stack().drop(5, level='SENSOR_ID')\n",
    "data_samp = temp_df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SENSOR_ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:00:00</td>\n",
       "      <td>18.449800</td>\n",
       "      <td>18.864667</td>\n",
       "      <td>18.753600</td>\n",
       "      <td>19.11130</td>\n",
       "      <td>18.6752</td>\n",
       "      <td>18.70705</td>\n",
       "      <td>18.386100</td>\n",
       "      <td>18.484100</td>\n",
       "      <td>18.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:02:00</td>\n",
       "      <td>18.440000</td>\n",
       "      <td>18.848333</td>\n",
       "      <td>18.756867</td>\n",
       "      <td>19.10640</td>\n",
       "      <td>18.6654</td>\n",
       "      <td>18.69235</td>\n",
       "      <td>18.378750</td>\n",
       "      <td>18.469400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:04:00</td>\n",
       "      <td>18.440000</td>\n",
       "      <td>18.832000</td>\n",
       "      <td>18.734000</td>\n",
       "      <td>19.10640</td>\n",
       "      <td>18.6654</td>\n",
       "      <td>18.68500</td>\n",
       "      <td>18.376300</td>\n",
       "      <td>18.475933</td>\n",
       "      <td>18.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.851600</td>\n",
       "      <td>18.753600</td>\n",
       "      <td>19.10640</td>\n",
       "      <td>18.6654</td>\n",
       "      <td>18.67765</td>\n",
       "      <td>18.377933</td>\n",
       "      <td>18.482467</td>\n",
       "      <td>18.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-01 00:08:00</td>\n",
       "      <td>18.435100</td>\n",
       "      <td>18.861400</td>\n",
       "      <td>18.773200</td>\n",
       "      <td>19.10150</td>\n",
       "      <td>18.6556</td>\n",
       "      <td>18.68500</td>\n",
       "      <td>18.371400</td>\n",
       "      <td>18.479200</td>\n",
       "      <td>18.433467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-10 08:58:00</td>\n",
       "      <td>22.835300</td>\n",
       "      <td>23.178300</td>\n",
       "      <td>23.776100</td>\n",
       "      <td>23.93045</td>\n",
       "      <td>24.0946</td>\n",
       "      <td>23.99170</td>\n",
       "      <td>25.296733</td>\n",
       "      <td>26.044800</td>\n",
       "      <td>24.473533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-10 09:00:00</td>\n",
       "      <td>22.879400</td>\n",
       "      <td>23.134200</td>\n",
       "      <td>23.717300</td>\n",
       "      <td>23.92800</td>\n",
       "      <td>24.1044</td>\n",
       "      <td>23.92800</td>\n",
       "      <td>25.395550</td>\n",
       "      <td>26.113400</td>\n",
       "      <td>24.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-10 09:02:00</td>\n",
       "      <td>22.869600</td>\n",
       "      <td>23.121950</td>\n",
       "      <td>23.676467</td>\n",
       "      <td>23.90840</td>\n",
       "      <td>24.1485</td>\n",
       "      <td>23.95740</td>\n",
       "      <td>25.496000</td>\n",
       "      <td>26.280000</td>\n",
       "      <td>24.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-10 09:04:00</td>\n",
       "      <td>22.836933</td>\n",
       "      <td>23.161150</td>\n",
       "      <td>23.673200</td>\n",
       "      <td>23.89370</td>\n",
       "      <td>24.1436</td>\n",
       "      <td>23.94760</td>\n",
       "      <td>25.518050</td>\n",
       "      <td>26.270200</td>\n",
       "      <td>24.709550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004-03-10 09:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.163600</td>\n",
       "      <td>23.653600</td>\n",
       "      <td>23.86920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.92800</td>\n",
       "      <td>25.505800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6754 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SENSOR_ID                   1          2          3         4        6   \\\n",
       "DATETIME                                                                  \n",
       "2004-03-01 00:00:00  18.449800  18.864667  18.753600  19.11130  18.6752   \n",
       "2004-03-01 00:02:00  18.440000  18.848333  18.756867  19.10640  18.6654   \n",
       "2004-03-01 00:04:00  18.440000  18.832000  18.734000  19.10640  18.6654   \n",
       "2004-03-01 00:06:00        NaN  18.851600  18.753600  19.10640  18.6654   \n",
       "2004-03-01 00:08:00  18.435100  18.861400  18.773200  19.10150  18.6556   \n",
       "...                        ...        ...        ...       ...      ...   \n",
       "2004-03-10 08:58:00  22.835300  23.178300  23.776100  23.93045  24.0946   \n",
       "2004-03-10 09:00:00  22.879400  23.134200  23.717300  23.92800  24.1044   \n",
       "2004-03-10 09:02:00  22.869600  23.121950  23.676467  23.90840  24.1485   \n",
       "2004-03-10 09:04:00  22.836933  23.161150  23.673200  23.89370  24.1436   \n",
       "2004-03-10 09:06:00        NaN  23.163600  23.653600  23.86920      NaN   \n",
       "\n",
       "SENSOR_ID                  7          8          9          10  \n",
       "DATETIME                                                        \n",
       "2004-03-01 00:00:00  18.70705  18.386100  18.484100  18.430200  \n",
       "2004-03-01 00:02:00  18.69235  18.378750  18.469400        NaN  \n",
       "2004-03-01 00:04:00  18.68500  18.376300  18.475933  18.400800  \n",
       "2004-03-01 00:06:00  18.67765  18.377933  18.482467  18.410600  \n",
       "2004-03-01 00:08:00  18.68500  18.371400  18.479200  18.433467  \n",
       "...                       ...        ...        ...        ...  \n",
       "2004-03-10 08:58:00  23.99170  25.296733  26.044800  24.473533  \n",
       "2004-03-10 09:00:00  23.92800  25.395550  26.113400  24.589500  \n",
       "2004-03-10 09:02:00  23.95740  25.496000  26.280000  24.692400  \n",
       "2004-03-10 09:04:00  23.94760  25.518050  26.270200  24.709550  \n",
       "2004-03-10 09:06:00  23.92800  25.505800        NaN        NaN  \n",
       "\n",
       "[6754 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some missing values, which we can simply deal with by applying linear interpolation to estimate values making our set continuous. Interpolation uses previous values, so for values appearing at the front of our frame (ie. sensor 1) we must make the process bidirectional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samp = data_samp.interpolate(method='linear', limit_direction='both', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SENSOR_ID\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SENSOR_ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "      <td>6754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>22.192462</td>\n",
       "      <td>22.126009</td>\n",
       "      <td>22.240772</td>\n",
       "      <td>22.249970</td>\n",
       "      <td>21.786615</td>\n",
       "      <td>21.844309</td>\n",
       "      <td>21.621812</td>\n",
       "      <td>21.801295</td>\n",
       "      <td>21.549061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.395218</td>\n",
       "      <td>1.944178</td>\n",
       "      <td>2.198261</td>\n",
       "      <td>2.049267</td>\n",
       "      <td>1.874288</td>\n",
       "      <td>1.955498</td>\n",
       "      <td>2.174163</td>\n",
       "      <td>2.258517</td>\n",
       "      <td>1.976967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>17.195400</td>\n",
       "      <td>17.642933</td>\n",
       "      <td>17.577600</td>\n",
       "      <td>18.038200</td>\n",
       "      <td>17.616800</td>\n",
       "      <td>17.789933</td>\n",
       "      <td>10.487300</td>\n",
       "      <td>17.499200</td>\n",
       "      <td>17.548200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>20.581300</td>\n",
       "      <td>20.881425</td>\n",
       "      <td>20.767500</td>\n",
       "      <td>20.988000</td>\n",
       "      <td>20.547612</td>\n",
       "      <td>20.574563</td>\n",
       "      <td>20.090075</td>\n",
       "      <td>20.143362</td>\n",
       "      <td>20.174600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>22.041500</td>\n",
       "      <td>22.259142</td>\n",
       "      <td>22.213000</td>\n",
       "      <td>22.046400</td>\n",
       "      <td>21.821000</td>\n",
       "      <td>21.742600</td>\n",
       "      <td>21.715650</td>\n",
       "      <td>21.811200</td>\n",
       "      <td>21.613567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>23.869200</td>\n",
       "      <td>23.349800</td>\n",
       "      <td>23.709133</td>\n",
       "      <td>23.437387</td>\n",
       "      <td>23.166867</td>\n",
       "      <td>23.178300</td>\n",
       "      <td>22.908800</td>\n",
       "      <td>23.152983</td>\n",
       "      <td>22.813250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>28.654867</td>\n",
       "      <td>27.416800</td>\n",
       "      <td>28.243267</td>\n",
       "      <td>27.652000</td>\n",
       "      <td>26.534800</td>\n",
       "      <td>26.420467</td>\n",
       "      <td>26.453950</td>\n",
       "      <td>27.162000</td>\n",
       "      <td>25.819400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SENSOR_ID           1            2            3            4            6   \\\n",
       "count      6754.000000  6754.000000  6754.000000  6754.000000  6754.000000   \n",
       "mean         22.192462    22.126009    22.240772    22.249970    21.786615   \n",
       "std           2.395218     1.944178     2.198261     2.049267     1.874288   \n",
       "min          17.195400    17.642933    17.577600    18.038200    17.616800   \n",
       "25%          20.581300    20.881425    20.767500    20.988000    20.547612   \n",
       "50%          22.041500    22.259142    22.213000    22.046400    21.821000   \n",
       "75%          23.869200    23.349800    23.709133    23.437387    23.166867   \n",
       "max          28.654867    27.416800    28.243267    27.652000    26.534800   \n",
       "\n",
       "SENSOR_ID           7            8            9            10  \n",
       "count      6754.000000  6754.000000  6754.000000  6754.000000  \n",
       "mean         21.844309    21.621812    21.801295    21.549061  \n",
       "std           1.955498     2.174163     2.258517     1.976967  \n",
       "min          17.789933    10.487300    17.499200    17.548200  \n",
       "25%          20.574563    20.090075    20.143362    20.174600  \n",
       "50%          21.742600    21.715650    21.811200    21.613567  \n",
       "75%          23.178300    22.908800    23.152983    22.813250  \n",
       "max          26.420467    26.453950    27.162000    25.819400  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data set smoothly tracks Temperature over a 2 minute interval without undefined data points. Let's plot our findings for each sensor in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x11a7519d0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11a9e2550>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11aacaad0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11ab09c90>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11ab407d0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11ab74e50>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11abb7510>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11abedb90>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x11abf6710>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_samp.plot(subplots=True, legend=True, figsize=(10,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Encoder-Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an array of 9 sensor values with readings at every 2 minute interval, we would like to generate a compressed representation of these values.\n",
    "\n",
    "Consider an input vector to out encoder of size 9, that takes the following form:\n",
    "\n",
    "$\\vec{S}=\\lbrace\\langle s_1, \\cdots, s_{n} \\rangle | s_k\\in S, 1\\leq k\\leq n\\rbrace$. Where $S$ is the set of sensors in our network that can transmit data to a gateway.\n",
    "\n",
    "Our autoencoder will attempt to encode a representation of $\\vec{S}$, shown as $h$ below, and use it to detect anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TEST](./img/autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are spatially clustering these sensors based on physical proximity to one another, but the overall size of $\\vec{S}$ is arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, RepeatVector, Dense, TimeDistributed\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will split our train/test sets. We will choose a 90/10 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (6078, 9), Testing shape: (676, 9)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data_samp, test_size=0.1)\n",
    "print('Training shape: {}, Testing shape: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrarily chosen look_back value\n",
    "look_back = 5\n",
    "n_features = train.shape[1]\n",
    "n_samples_train = train.shape[0] - lookback\n",
    "n_samples_test = test.shape[0] - lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Train: (6073, 5, 9), reshaped Test: (671, 5, 9)\n"
     ]
    }
   ],
   "source": [
    "train_reshape = np.zeros((n_samples_train, look_back, n_features))\n",
    "test_reshape = np.zeros((n_samples_test, look_back, n_features))\n",
    "\n",
    "for i in range(n_samples_train):\n",
    "    train_reshape[i] = train[i:i+look_back]\n",
    "\n",
    "for j in range(n_samples_test):\n",
    "    test_reshape[j] = test[j:j+look_back]\n",
    "\n",
    "print('Reshaped Train: {}, reshaped Test: {}'.format(train_reshape.shape, test_reshape.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(reshaped_data):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, activation='relu', input_shape=(reshaped_data.shape[1], reshaped_data.shape[2])))\n",
    "    model.add(RepeatVector(reshaped_data.shape[1]))\n",
    "    model.add(LSTM(units=128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(units=reshaped_data.shape[2])))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 5, 9)              1161      \n",
      "=================================================================\n",
      "Total params: 203,401\n",
      "Trainable params: 203,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(train_reshape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the test data subset into an even smaller validation split for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5465 samples, validate on 608 samples\n",
      "Epoch 1/10\n",
      "5465/5465 [==============================] - 6s 1ms/step - loss: 29.1600 - val_loss: 2.6725\n",
      "Epoch 2/10\n",
      "5465/5465 [==============================] - 5s 889us/step - loss: 2.0432 - val_loss: 1.3379\n",
      "Epoch 3/10\n",
      "5465/5465 [==============================] - 5s 896us/step - loss: 0.9571 - val_loss: 0.4820\n",
      "Epoch 4/10\n",
      "5465/5465 [==============================] - 5s 909us/step - loss: 0.3871 - val_loss: 0.3485\n",
      "Epoch 5/10\n",
      "5465/5465 [==============================] - 5s 906us/step - loss: 0.3093 - val_loss: 0.2807\n",
      "Epoch 6/10\n",
      "5465/5465 [==============================] - 5s 922us/step - loss: 0.2623 - val_loss: 0.2388\n",
      "Epoch 7/10\n",
      "5465/5465 [==============================] - 6s 1ms/step - loss: 0.2545 - val_loss: 0.2151\n",
      "Epoch 8/10\n",
      "5465/5465 [==============================] - 5s 971us/step - loss: 0.2404 - val_loss: 0.2380\n",
      "Epoch 9/10\n",
      "5465/5465 [==============================] - 5s 905us/step - loss: 0.2220 - val_loss: 0.2001\n",
      "Epoch 10/10\n",
      "5465/5465 [==============================] - 5s 891us/step - loss: 0.2162 - val_loss: 0.2128\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_reshape, train_reshape,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
